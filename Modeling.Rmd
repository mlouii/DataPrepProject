```{r}
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(ROCR)
```

```{r}
set.seed(100)
curDir <- '/Users/aakef/Documents/School/csp571/DataPrepProject'
setwd(curDir)
#library(ggplot2)
library(tidyverse)
data.raw1 <- read.csv(file='dataset-of-00s.csv')
data.raw2 <- read.csv(file='dataset-of-10s.csv')
data.raw3 <- read.csv(file='dataset-of-60s.csv')
data.raw4 <- read.csv(file='dataset-of-70s.csv')
data.raw5 <- read.csv(file='dataset-of-80s.csv')
data.raw6 <- read.csv(file='dataset-of-90s.csv')



wholeIndex <- createDataPartition(data.raw1$target, times=1, p=0.8, list=FALSE)
FINAL_TEST.raw1<- data.raw1[-wholeIndex,]
data.raw1 <- data.raw1[wholeIndex,]


wholeIndex <- createDataPartition(data.raw2$target, times=1, p=0.8, list=FALSE)
FINAL_TEST.raw2<- data.raw2[-wholeIndex,]
data.raw2 <- data.raw2[wholeIndex,]

wholeIndex <- createDataPartition(data.raw3$target, times=1, p=0.8, list=FALSE)
FINAL_TEST.raw3 <- data.raw3[-wholeIndex,]
data.raw3 <- data.raw3[wholeIndex,]

wholeIndex <- createDataPartition(data.raw4$target, times=1, p=0.8, list=FALSE)
FINAL_TEST.raw4<- data.raw4[-wholeIndex,]
data.raw4 <- data.raw4[wholeIndex,]

wholeIndex <- createDataPartition(data.raw5$target, times=1, p=0.8, list=FALSE)
FINAL_TEST.raw5<- data.raw5[-wholeIndex,]
data.raw5 <- data.raw5[wholeIndex,]

wholeIndex <- createDataPartition(data.raw6$target, times=1, p=0.8, list=FALSE)
FINAL_TEST.raw6<- data.raw6[-wholeIndex,]
data.raw6 <- data.raw6[wholeIndex,]


#Combine all data sorces together
FINAL_TEST.raw <- ( rbind(FINAL_TEST.raw1,FINAL_TEST.raw2) %>% rbind(FINAL_TEST.raw3) %>% rbind(FINAL_TEST.raw4)
  %>% rbind(FINAL_TEST.raw5) %>% rbind(FINAL_TEST.raw6) )


data.raw <- ( rbind(data.raw1,data.raw2) %>% rbind(data.raw3) %>% rbind(data.raw4)
  %>% rbind(data.raw5) %>% rbind(data.raw6) )
```

```{r}
class(data.raw)
dim(data.raw)
str(data.raw)

#Check entire table for NA values
table(is.na(data.raw))
#See where NA values lies
colSums(is.na(data.raw))
#Omit NA values
data.raw1<-na.omit(data.raw)
#Get the summary of the dataset
summary(data.raw)
#Remove unnecessary columns
data.raw<-data.raw %>% select(-c(track,artist,uri))
data.raw1<-data.raw1 %>% select(-c(track,artist,uri))
data.raw2<-data.raw2 %>% select(-c(track,artist,uri))
data.raw3<-data.raw3 %>% select(-c(track,artist,uri))
data.raw4<-data.raw4 %>% select(-c(track,artist,uri))
data.raw5<-data.raw5 %>% select(-c(track,artist,uri))
data.raw6<-data.raw6 %>% select(-c(track,artist,uri))



FINAL_TEST.raw<-FINAL_TEST.raw %>% select(-c(track,artist,uri))
FINAL_TEST.raw1<-FINAL_TEST.raw1 %>% select(-c(track,artist,uri))
FINAL_TEST.raw2<-FINAL_TEST.raw2 %>% select(-c(track,artist,uri))
FINAL_TEST.raw3<-FINAL_TEST.raw3 %>% select(-c(track,artist,uri))
FINAL_TEST.raw4<-FINAL_TEST.raw4 %>% select(-c(track,artist,uri))
FINAL_TEST.raw5<-FINAL_TEST.raw5 %>% select(-c(track,artist,uri))
FINAL_TEST.raw6<-FINAL_TEST.raw6 %>% select(-c(track,artist,uri))
```

```{r}
trainIndex <- createDataPartition(data.raw$target, times=1, p=0.8, list=FALSE)
train <- data.raw[trainIndex,]
test <- data.raw[-trainIndex,]
fitted <- glm(target~., data=data.raw, family = "binomial")
```

```{r}
summary(fitted)[["coefficients"]]
```

Danceability and Speechiness seem to most correlated with a song being a hit across time

```{r}
probs <- predict(fitted,newdata=test, type = "response")
preds <- ifelse(probs > 0.5, 1, 0)
actuals = as.integer(test$target == 1, 1, 0)
confusionMatrix(data=as.factor(preds), reference=as.factor(actuals))
```

![]()

Using all the variables we get a 72% accuracy

Let's try retraining the model with variables that only got coeeficients \>= \|1\|

```{r}
trainIndex <- createDataPartition(data.raw$target, times=1, p=0.8, list=FALSE)
train <- data.raw[trainIndex,]
test <- data.raw[-trainIndex,]
fitted_some <- glm(target~danceability+energy+speechiness+acousticness+instrumentalness, data=data.raw, family = "binomial")

probs <- predict(fitted_some,newdata=test, type = "response")
preds <- ifelse(probs > 0.5, 1, 0)
actuals = as.integer(test$target == 1, 1, 0)
confusionMatrix(data=as.factor(preds), reference=as.factor(actuals))
```

We get a slightly lower accuracy using a third of the features

```{r}
summary(fitted_some)[["coefficients"]]
```

```{r}
#data.raw3<-data.raw3 %>% select(-c(track,artist,uri))
trainIndex6 <- createDataPartition(data.raw3$target, times=1, p=0.8, list=FALSE)
train6 <- data.raw3[trainIndex6,]
test6 <- data.raw3[-trainIndex6,]
fitted6 <- glm(target~., data=data.raw3, family = "binomial")

```

```{r}
summary(fitted6)[["coefficients"]]
```

Speechiness was a lot more valued in the 60s

```{r}
probs <- predict(fitted6,newdata=test, type = "response")
preds <- ifelse(probs > 0.5, 1, 0)
actuals = as.integer(test$target == 1, 1, 0)
confusionMatrix(data=as.factor(preds), reference=as.factor(actuals))
```

![]()

```{r}
#data.raw2<-data.raw2 %>% select(-c(track,artist,uri))
trainIndex10 <- createDataPartition(data.raw2$target, times=1, p=0.8, list=FALSE)
train10 <- data.raw2[trainIndex10,]
test10 <- data.raw2[-trainIndex10,]
fitted10 <- glm(target~., data=data.raw2, family = "binomial")
```

```{r}
summary(fitted10)[["coefficients"]]
```

In the 2010s dancebility and energy are a lot more popular than in the 60s

```{r}
probs <- predict(fitted10,newdata=test, type = "response")
preds <- ifelse(probs > 0.5, 1, 0)
actuals = as.integer(test$target == 1, 1, 0)
confusionMatrix(data=as.factor(preds), reference=as.factor(actuals))
```

Tree Models

```{r}
trainIndex_tree <- createDataPartition(data.raw$target, times=1, p=0.8, list=FALSE)
train_tree <- data.raw[trainIndex_tree,]
test_tree <- data.raw[-trainIndex_tree,]
tree <-rpart(target~., data=train_tree, method="class")
rpart.plot(tree)
```

With the tree model the most discriminatory feature was insturmentalness

```{r}
predst <- predict(tree,newdata=test_tree, type = "class")

actualst = test_tree$target
confusionMatrix(data=as.factor(predst), reference=as.factor(actualst))
```

![]()Decision tree has a slightly better performance than the linear regression

```{r}
train_tree$target = as.factor(train_tree$target)
```

```{r}

classifier_RF = randomForest(target~., data=train_tree, ntree=100)
```

```{r}

predsrf <- as.factor(predict(classifier_RF,newdata=test_tree, type = "class"))

#actualst = as.integer(test_tree$target == 1, 1, 0)
confusionMatrix(data=(predsrf), reference=(as.factor(actualst)))
```

```{r}
classifier_RF = randomForest(target~danceability+energy+speechiness+acousticness+instrumentalness, data=train_tree, ntree=100)
```

```{r}
predsrf <- as.factor(predict(classifier_RF,newdata=test_tree, type = "class"))

#actualst = as.integer(test_tree$target == 1, 1, 0)
confusionMatrix(data=(predsrf), reference=(as.factor(actualst)))
```

```{r}
final_probs <- predict(fitted_some,newdata=FINAL_TEST.raw, type = "response")
final_preds<- ifelse(final_probs > 0.5, 1, 0)
actuals = FINAL_TEST.raw$target
confusionMatrix(data=as.factor(final_preds), reference=as.factor(actuals))
```

```{r}

fpreds <- prediction(final_preds, actuals)
roc = performance(fpreds,"tpr","fpr")
plot(roc, colorize = T, lwd = 2)
abline(a = 0, b = 1) 
auc = performance(fpreds, measure = "auc")
```

```{r}
auc@y.values
```

```{r}
modern_test <- read.csv(file='test.csv')
test_probs <- predict(fitted_some,newdata=modern_test, type = "response")
test_preds<- ifelse(test_probs > 0.5, 1, 0)
test_true <-  modern_test$target

test_preds
test_probs
```

```{r}
test_probs6 <- predict(fitted6,newdata=modern_test, type = "response")
test_preds6<- ifelse(test_probs6 > 0.5, 1, 0)
test_preds6
test_probs6 
```

```{r}
modern_test
```
